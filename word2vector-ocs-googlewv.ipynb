{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "\n",
    "# df = pd.read_csv('stack-overflow-data.csv')\n",
    "# df = df[pd.notnull(df['tags'])]\n",
    "# print(df.head(10))\n",
    "# print(df['post'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['post'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "def get_tweet_text_from_json(file_path):\n",
    "    events = []\n",
    "    labels = []\n",
    "    with open(file_path) as json_file:\n",
    "#         pdb.set_trace()\n",
    "        data = json.load(json_file)\n",
    "        for key, value in data.items():\n",
    "            events.append(value[\"text\"])\n",
    "            labels.append(value[\"label\"])\n",
    "        return events,labels\n",
    "    \n",
    "def get_tweet_text_from_json_unlabel(file_path):\n",
    "    events = []\n",
    "    with open(file_path) as json_file:\n",
    "#         pdb.set_trace()\n",
    "        data = json.load(json_file)\n",
    "        for key, value in data.items():\n",
    "            events.append(value[\"text\"])\n",
    "        return events\n",
    "    \n",
    "misinfo_train_events,misinfo_train_labels = get_tweet_text_from_json(\"train.json\")\n",
    "dev_events,dev_labels = get_tweet_text_from_json(\"dev.json\")\n",
    "test_unlabel = get_tweet_text_from_json_unlabel(\"test-unlabelled.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_info = [i for i,x in enumerate(dev_labels) if x==0]\n",
    "# print(dev_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_abbrevation(text):\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"cannot\", \"can not \", text)\n",
    "    text = re.sub(r\"what\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"What\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'ve \", \" have \", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not \", text)\n",
    "    text = re.sub(r\"i\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"I\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e mail \", \" email \", text)\n",
    "    text = re.sub(r\" e \\- mail \", \" email \", text)\n",
    "    text = re.sub(r\" e\\-mail \", \" email \", text)\n",
    "    \n",
    "    text = re.sub(r\"what're\", \"can not\", text)\n",
    "    text = re.sub(r\"cannot\", \"can not \", text)\n",
    "    text = re.sub(r\"what\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"What\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'ve \", \" have \", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not \", text)\n",
    "    text = re.sub(r\"i\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"I\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e mail \", \" email \", text)\n",
    "    text = re.sub(r\" e \\- mail \", \" email \", text)\n",
    "    text = re.sub(r\" e\\-mail \", \" email \", text)\n",
    "        \n",
    "punctuation='[\"\\'?,\\.]' # I will replace all these punctuation with ''\n",
    "abbr_dict={\n",
    "    \"what's\":\"what is\",\n",
    "    \"what're\":\"what are\",\n",
    "    \"who's\":\"who is\",\n",
    "    \"who're\":\"who are\",\n",
    "    \"where's\":\"where is\",\n",
    "    \"where're\":\"where are\",\n",
    "    \"when's\":\"when is\",\n",
    "    \"when're\":\"when are\",\n",
    "    \"how's\":\"how is\",\n",
    "    \"how're\":\"how are\",\n",
    "\n",
    "    \"i'm\":\"i am\",\n",
    "    \"we're\":\"we are\",\n",
    "    \"you're\":\"you are\",\n",
    "    \"they're\":\"they are\",\n",
    "    \"it's\":\"it is\",\n",
    "    \"he's\":\"he is\",\n",
    "    \"she's\":\"she is\",\n",
    "    \"that's\":\"that is\",\n",
    "    \"there's\":\"there is\",\n",
    "    \"there're\":\"there are\",\n",
    "\n",
    "    \"i've\":\"i have\",\n",
    "    \"we've\":\"we have\",\n",
    "    \"you've\":\"you have\",\n",
    "    \"they've\":\"they have\",\n",
    "    \"who've\":\"who have\",\n",
    "    \"would've\":\"would have\",\n",
    "    \"not've\":\"not have\",\n",
    "\n",
    "    \"i'll\":\"i will\",\n",
    "    \"we'll\":\"we will\",\n",
    "    \"you'll\":\"you will\",\n",
    "    \"he'll\":\"he will\",\n",
    "    \"she'll\":\"she will\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"they'll\":\"they will\",\n",
    "\n",
    "    \"isn't\":\"is not\",\n",
    "    \"wasn't\":\"was not\",\n",
    "    \"aren't\":\"are not\",\n",
    "    \"weren't\":\"were not\",\n",
    "    \"can't\":\"can not\",\n",
    "    \"couldn't\":\"could not\",\n",
    "    \"don't\":\"do not\",\n",
    "    \"didn't\":\"did not\",\n",
    "    \"shouldn't\":\"should not\",\n",
    "    \"wouldn't\":\"would not\",\n",
    "    \"doesn't\":\"does not\",\n",
    "    \"haven't\":\"have not\",\n",
    "    \"hasn't\":\"has not\",\n",
    "    \"hadn't\":\"had not\",\n",
    "    \"won't\":\"will not\",\n",
    "    punctuation:'',\n",
    "    '\\s+':' ', # replace multi space with one single space\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-5-17214cb86a31>(9)<module>()\n",
      "-> rep = [abbr_dict[x] if x in abbr_dict else x for x in tokenize_words]\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(5)<module>()\n",
      "-> for event in misinfo_train_events:\n",
      "(Pdb) rep\n",
      "['why', 'houston', 'flooding', 'isn‘t', 'a', 'sign', 'of', 'climate', 'change', 'Distinguished', 'US', 'climate', 'scientist,', 'Dr', 'Roy', 'Spencer', 'writes:', '\"In', 'the', 'context', 'of', 'climate', 'change,', 'is', 'what', 'we', 'are', 'seeing', 'in', 'Houston', 'a', 'new', 'level', 'of', 'disaster', 'which', 'is', 'becoming', 'more', 'common?', 'The', 'flood', 'disaster', 'unfolding', 'in', 'Houston', 'is', 'certainly', 'very', 'unusual.', 'But', 'so', 'are', 'other', 'natural', 'weather', 'disasters,', 'which', 'have', 'always', 'occurred', 'and', 'always', 'will', 'occur....Major', 'floods', 'are', 'difficult', 'to', 'compare', 'throughout', 'history', 'because', 'of', 'the', 'ways', 'we', 'alter', 'the', 'landscape.,', 'For', 'example,', 'as', 'cities', 'like', 'Houston', 'expand', 'over', 'the', 'years,', 'soil', 'is', 'covered', 'up', 'by', 'roads,', 'parking', 'lots', 'and', 'buidings,', 'with', 'water', 'rapidly', 'draining', 'off', 'rather', 'than', 'soaking', 'into', 'the', 'soil.', 'The', 'population', 'of', 'Houston', 'is', 'now', 'ten', 'times', 'what', 'is', 'was', 'in', 'the', '1920s.', 'The', 'Houston', 'metroplex', 'has', 'expanded', 'greatly', 'and', 'the', 'water', 'drainage', 'is', 'basically', 'in', 'the', 'direction', 'of', 'downtown', 'Houston.\"']\n",
      "(Pdb) 'isn't' == 'isn‘t'\n",
      "*** SyntaxError: invalid syntax\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(6)<module>()\n",
      "-> event_re = event.replace(\"\\n\",\" \")\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(7)<module>()\n",
      "-> tokenize_words = event_re.split()\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(8)<module>()\n",
      "-> pdb.set_trace()\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(9)<module>()\n",
      "-> rep = [abbr_dict[x] if x in abbr_dict else x for x in tokenize_words]\n",
      "(Pdb) n\n",
      "> <ipython-input-5-17214cb86a31>(5)<module>()\n",
      "-> for event in misinfo_train_events:\n",
      "(Pdb) rep\n",
      "['The', 'U.N.', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', '(IPCC)', 'released', '“Global', 'Warming', 'of', '1.5', 'C,”', 'dubbed', 'SR15,', 'an', 'IPCC', 'special', 'report', 'last', 'week,', 'claiming', 'that,', 'unless', 'governments', 'virtually', 'eliminate', 'human', 'production', 'of', 'carbon', 'dioxide', '(CO2),', 'we', 'are', 'headed', 'toward', 'a', 'climate', 'catastrophe.', 'The', 'UK’s', 'The', 'Guardian', 'reported', 'that', 'the', 'report', 'authors', 'say,', '“urgent', 'and', 'unprecedented', 'changes', 'are', 'needed', 'to', 'reach', 'the', 'target,', 'which', 'they', 'say', 'is', 'affordable', 'and', 'feasible', 'although', 'it', 'lies', 'at', 'the', 'most', 'ambitious', 'end', 'of', 'the', 'Paris', 'Agreement', 'pledge', 'to', 'keep', 'temperatures', 'between', '1.5C', 'and', '2C.”', 'The', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'climate', 'forecasts', 'were', 'wrong', 'from', 'their', 'earliest', 'reports', 'in', '1990.', 'They', 'were', 'so', 'inaccurate', 'that', 'they', 'stopped', 'calling', 'them', 'forecasts', 'and', 'made', 'three', '“projections”:', 'low,', 'medium,', 'and', 'high.', 'Since', 'then,', 'even', 'their', '“low”', 'scenario', 'projections', 'were', 'wrong.', 'The', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'created', 'an', 'illusion', 'of', 'certainty', 'about', 'their', 'science,', 'and', 'therefore', 'their', 'forecasts.', 'They', 'let', 'people', 'think', 'that', 'they', 'study', 'all', 'causes', 'of', 'climate', 'change', 'when', 'they', 'only', 'look', 'at', 'human-caused', 'change.', 'That', 'is', 'impossible', 'unless', 'you', 'know', 'and', 'understand', 'total', 'climate', 'change', 'and', 'the', 'mechanisms,', 'and', 'we', 'don’t.', 'It', 'allowed', 'them', 'to', 'ignore', 'all', 'non-human', 'causes', 'of', 'change,', 'including', 'the', 'Sun.', 'One', 'of', 'the', 'reasons', 'the', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'gets', 'away', 'with', 'this', 'is', 'that', 'almost', 'no', 'one', 'reads', 'the', 'underlying', 'science', 'reports.', 'Indeed,', 'the', '“Final', 'Government', 'Draft”', 'of', 'the', 'underlying', 'science', 'report,', 'which', 'appears', 'on', 'the', 'IPCC', 'Web', 'site,', 'even', 'cautions', 'the', 'reader,', '“Do', 'Not', 'Cite,', 'Quote', 'or', 'Distribute.”', 'Partly', 'for', 'this', 'reason,', 'but', 'mainly', 'because', 'the', 'underlying', 'science', 'reports', 'are', 'so', 'complicated,', 'media', 'and', 'politicians', 'rely', 'instead', 'on', 'the', 'SR15', 'Summary', 'for', 'Policymakers', '(SPM).', 'This', 'document', 'is', 'written', 'mostly', 'by', 'government', 'representatives', 'and', 'also', 'has', 'to', 'be', 'approved', 'by', 'them.', 'The', 'SPM', 'is', 'consequently', 'a', 'highly', 'political', 'document', 'that', 'fulfils', 'policy', 'objectives', 'of', 'the', 'member', 'governments', 'and', 'typically', 'does', 'not', 'properly', 'reflect', 'uncertainties', 'in', 'the', 'underlying', 'science.', 'Writing', 'in', '2002', 'about', 'the', 'SPM', 'of', 'Working', 'Group', 'I', 'of', 'the', 'IPCC', 'Third', 'Assessment', 'Report,', 'IPCC', 'Reviewer', 'and', 'independent', 'analyst', 'David', 'Wojick', 'explained', 'the', 'sort', 'of', 'problems', 'typical', 'of', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'summary', 'reports:', 'What', 'is', 'systematically', 'omitted', 'from', 'the', 'Summary', 'for', 'Policymakers', 'are', 'precisely', 'the', 'uncertainties', 'and', 'positive', 'counter', 'evidence', 'that', 'might', 'negate', 'the', 'human', 'interference', 'theory.', 'Instead', 'of', 'assessing', 'these', 'objections,', 'the', 'Summary', 'confidently', 'asserts', 'just', 'those', 'findings', 'that', 'support', 'its', 'case.', 'In', 'short,', 'this', 'is', 'advocacy,', 'not', 'assessment.', 'Having', 'tracked', 'the', 'evolution', 'of', 'SR15', 'for', 'the', 'past', 'six', 'months,', 'Mr.', 'Wojick', 'says', 'that', 'this', 'is', 'exactly', 'what', 'has', 'happened', 'on', 'this', 'latest', 'report', 'as', 'well.', 'The', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'procedures', 'allow', 'government', 'representatives', 'to', 'ultimately', 'control', 'the', 'underlying', 'science', 'reports', 'as', 'well', 'by', 'specifying', 'that', 'changes', 'to', 'the', 'science', 'reports', 'may', 'be', 'made', 'even', 'after', 'they', 'have', 'been', 'approved', '“to', 'ensure', 'consistency', 'with', 'the', 'Summary', 'for', 'Policymakers.”', 'In', 'fact,', 'when', 'releasing', 'the', 'Final', 'Government', 'Draft', 'of', 'the', 'underlying', 'science', 'report', 'for', 'SR15,', 'the', 'IPCC', 'specifies', 'that', 'it', 'is', '“Subject', 'to', 'correction,', 'copy-editing,', 'layout', 'and', '‘trickleback.’”', 'Trickleback', 'is', 'adjustments', 'to', 'the', 'text', 'of', 'the', 'science', 'report', 'to', 'assure', 'that', 'it', 'conforms', 'with', 'the', 'approved', 'SPM.', 'Mr.', 'Wojick', 'laughs,', 'pointing', 'out', 'that', '“trickleback”', 'begins', 'with', '“trick.”', 'Although', 'the', 'Intergovernmental', 'Panel', 'on', 'Climate', 'Change', 'asserts', 'in', 'the', 'SR15', 'trickleback', 'report', 'that', '“These', 'changes', 'do', 'not', 'alter', 'any', 'substantive', 'findings', 'of', 'the', 'final', 'draft', 'of', 'the', 'underlying', 'report,”', 'considering', 'the', 'contrast', 'between', 'past', 'IPCC', 'SPMs', 'and', 'the', 'underlying', 'science', 'reports,', 'this', 'is', 'difficult', 'to', 'believe.', 'Regardless,', 'the', 'complexity', 'of', 'this', 'process', 'ensures', 'that,', 'like', 'the', 'science', 'report', 'itself,', 'virtually', 'no', 'one', 'reads', 'the', 'trickleback', 'document', 'to', 'see', 'where', 'the', 'science', 'report', 'has', 'been', 'changed.', 'The', 'scientific', 'section', 'of', 'the', 'IPCC', 'Third', 'Assessment', 'Report', 'illustrates', 'how', 'little', 'they', 'actually', 'know', 'about', 'climate', 'futures:', 'In', 'climate', 'research', 'and', 'modelling,', 'we', 'should', 'recognize', 'that', 'we', 'are', 'dealing', 'with', 'a', 'coupled', 'non-linear', 'chaotic', 'system,', 'and', 'therefore', 'that', 'the', 'long-term', 'prediction', 'of', 'future', 'climate', 'states', 'is', 'not', 'possible.', 'The', 'supposed', 'threat', 'is', 'a', '1.5', 'to', '2C', 'increase,', 'but', 'global', 'temperatures', 'were', 'higher', 'than', 'today', 'by', 'at', 'least', 'that', 'much', 'for', 'most', 'of', 'the', 'last', '10,000', 'years.', 'Yet', 'polar', 'bears', 'and', 'the', 'world', 'survived.', 'No', 'one', 'should', 'take', 'the', 'new', 'IPCC', 'climate', 'report', 'seriously.', '[Originally', 'Published', 'at', 'The', 'Washington', 'Times]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) quit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-17214cb86a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmisinfo_train_events_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmisinfo_train_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mevent_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenize_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-17214cb86a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmisinfo_train_events_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmisinfo_train_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mevent_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenize_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# misinfo_train_events.replace(abbr_dict,regex=True,inplace=True)\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "misinfo_train_events_new = []\n",
    "for event in misinfo_train_events:\n",
    "    event_re = event.replace(\"\\n\",\" \")\n",
    "    tokenize_words = event_re.split()\n",
    "    pdb.set_trace()\n",
    "    rep = [abbr_dict[x] if x in abbr_dict else x for x in tokenize_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(misinfo_train_events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_plot(index):\n",
    "#     example = df[df.index == index][['post', 'tags']].values[0]\n",
    "#     if len(example) > 0:\n",
    "#         print(example[0])\n",
    "#         print('Tag:', example[1])\n",
    "# print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "#     text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "#     pdb.set_trace()\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "    \n",
    "# df['post'] = df['post'].apply(clean_text)\n",
    "# print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'themselves', \"should've\", 'is', 'same', 'been', 'haven', 'with', 'shouldn', 'ain', 'most', 'myself', 'for', 'than', 'we', \"don't\", \"isn't\", 'him', 'he', 'as', 'few', 'where', \"you're\", 'my', 're', \"it's\", 'was', \"you'd\", \"hasn't\", 'hasn', 'their', 'doing', 'this', 'by', \"wasn't\", 'm', 'against', 'each', \"mightn't\", 'won', 'only', 'any', 'will', 'down', 'why', 'were', 'over', 'a', 't', 'theirs', 'yours', 'under', 'needn', \"mustn't\", \"doesn't\", 'own', \"weren't\", 'to', 'don', 'further', 'there', 'mustn', 'more', 'these', 'or', 'other', 'herself', 'having', 'from', \"won't\", 'those', 'shan', 'll', 'before', 'ma', 'whom', 'hadn', 'and', 'of', \"needn't\", 'his', 'what', 'not', \"you'll\", 'between', 'just', 'who', \"wouldn't\", 'the', 'isn', 'in', 'it', 'her', \"shan't\", 'nor', 'y', 'o', 'should', 'wasn', 'if', 'out', 've', 'them', \"that'll\", 'are', 'weren', 'ours', 'then', 'during', 'no', 'mightn', 'does', 'but', 'you', 'its', 'which', 's', 'all', 'itself', \"shouldn't\", 'wouldn', 'himself', 'up', 'through', 'when', 'do', 'off', 'have', 'so', 'our', 'some', 'didn', 'once', 'couldn', 'me', 'now', 'because', 'that', 'at', 'below', \"she's\", \"couldn't\", 'above', 'be', 'here', 'had', 'into', 'about', \"haven't\", 'such', 'has', \"aren't\", 'can', 'until', 'am', 'too', 'very', 'd', 'your', 'again', 'yourself', 'doesn', 'she', 'they', 'ourselves', 'after', 'while', \"didn't\", 'being', \"hadn't\", 'yourselves', 'aren', 'did', 'on', \"you've\", 'both', 'hers', 'an', 'how', 'i'}\n"
     ]
    }
   ],
   "source": [
    "print('just' in STOPWORDS)\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,event in enumerate(misinfo_train_events):\n",
    "    misinfo_train_events[i] = clean_text(misinfo_train_events[i])\n",
    "for i,event in enumerate(dev_events):\n",
    "    dev_events[i] = clean_text(dev_events[i])\n",
    "for i,event in enumerate(test_unlabel):\n",
    "    test_unlabel[i] = clean_text(test_unlabel[i])\n",
    "# print(misinfo_train_events[0])\n",
    "# print(dev_events[0])\n",
    "# print(test_unlabel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "# train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
    "\n",
    "train_tokenized = []\n",
    "dev_tokenized = []\n",
    "test_tokenized = []\n",
    "for event in misinfo_train_events:\n",
    "    train_tokenized.append(w2v_tokenize_text(event))\n",
    "for event in dev_events:\n",
    "    dev_tokenized.append(w2v_tokenize_text(event))\n",
    "for event in test_unlabel:\n",
    "    test_tokenized.append(w2v_tokenize_text(event))  \n",
    "# test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
    "# train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_dev_word_average = word_averaging_list(wv,dev_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_tokenized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_result(groundtruth, prediction):\n",
    "    prediction = prediction.tolist()\n",
    "    for i,item in enumerate(prediction):\n",
    "        if item == -1:\n",
    "            prediction[i] = 0\n",
    "    p, r, f, _ = precision_recall_fscore_support(groundtruth, prediction, pos_label=1, average=\"binary\")\n",
    "#     pdb.set_trace()\n",
    "    print(\"Performance on the positive class (documents with misinformation):\")\n",
    "    print(\"Precision =\", p)\n",
    "    print(\"Recall    =\", r)\n",
    "    print(\"F1        =\", f)\n",
    "    print(accuracy_score(dev_labels,prediction))\n",
    "    \n",
    "def transfer_output(preds):\n",
    "    test_dic = {}\n",
    "    for i,test_pre in enumerate(preds):\n",
    "        if test_pre == -1:\n",
    "            dic = {}\n",
    "            dic['label'] = 0\n",
    "    #         pdb.set_trace()\n",
    "            test_dic['test-%s'%(i)] = dic\n",
    "        else:\n",
    "            dic = {}\n",
    "    #         pdb.set_trace()\n",
    "            dic['label'] = 1\n",
    "            test_dic['test-%s'%(i)] = dic\n",
    "    jstr = json.dumps(test_dic,ensure_ascii = False)\n",
    "    # print(jstr)\n",
    "    with open('test-output.json','w') as f:\n",
    "        f.write(jstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5154639175257731\n",
      "Recall    = 1.0\n",
      "F1        = 0.6802721088435374\n",
      "0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6125\n",
      "Recall    = 0.98\n",
      "F1        = 0.7538461538461539\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "nus = [0.001, 0.01, 0.1, 1]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['rbf','linear']\n",
    "for kernel in kernels:\n",
    "    for nu in nus:\n",
    "        for gamma in gammas:\n",
    "            ocs = svm.OneClassSVM(gamma=gamma,kernel = kernel, nu = nu).fit(X_train_word_average)\n",
    "            y_pre = ocs.predict(X_dev_word_average)\n",
    "            print(ocs)\n",
    "            evaluate_result(dev_labels,y_pre)\n",
    "# logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "# logreg = logreg.fit(X_train_word_average, misinfo_train_labels)\n",
    "# # y_pred = logreg.predict(X_dev_word_average)\n",
    "# print('accuracy %s' % accuracy_score(y_pred, test.tags))\n",
    "# print(classification_report(test.tags, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "ocs = svm.OneClassSVM(gamma=0.001,kernel = 'rbf', nu = 0.1).fit(X_train_word_average)\n",
    "test_pres = ocs.predict(X_test_word_average)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################own#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/models/base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "all_texts = train_tokenized + dev_tokenized + test_tokenized\n",
    "word_model = Word2Vec(all_texts, min_count=2, size=100, window=8, iter=100, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/models/base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "all_texts = train_tokenized + dev_tokenized + test_tokenized\n",
    "word_model_skip_gram = Word2Vec(all_texts, min_count=2, size=60, window=8, iter=50, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_skip_gram.save(\"word_model_skip_gram.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_skip_gram = gensim.models.word2vec.Word2Vec.load(\"word_model_skip_gram.w2v\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "punc = punctuation + u'.,;《》？！“”‘’@#￥%…&×（）——+【】{};；●，。&～、|\\s:：'\n",
    "# exclude = set(punc)\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if (treebank_tag.startswith('J'))|(treebank_tag =='ADJ'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif (treebank_tag.startswith('R'))|(treebank_tag=='ADV'):\n",
    "        return wordnet.ADV\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def preprocess_drop_punc_evnets(events):\n",
    "#     preprocess_drop_punc_evnets = events\n",
    "    preprocess_drop_punc_evnets = []\n",
    "#     pdb.set_trace()\n",
    "    for event in events:\n",
    "        event_re = re.sub(r\"[{}]+\".format(punc),\" \",event)\n",
    "        preprocess_drop_punc_evnets.append(event_re)\n",
    "    return preprocess_drop_punc_evnets\n",
    "\n",
    "def preprocess_stopwords_lemma_evnets(events):\n",
    "    preprocess_BOW_events = []\n",
    "    preprocess_events = []\n",
    "    preprocess_events_tokens = []\n",
    "#     pdb.set_trace()\n",
    "    after_drop_punc_evnets = preprocess_drop_punc_evnets(events)\n",
    "    for event in after_drop_punc_evnets:\n",
    "        dic_bow = defaultdict(int)\n",
    "        tokenize_words = tt.tokenize(event)\n",
    "#         rep = [abbr_dict[x] if x in abbr_dict else x for x in tokenize_words]\n",
    "        words_pos = nltk.pos_tag(tokenize_words, tagset=\"universal\")\n",
    "#         pdb.set_trace()\n",
    "        filter_event = [(w,pos) for (w,pos) in words_pos if w.lower() not in stopwords]\n",
    "        lemma_event = []\n",
    "        for (word,pos) in filter_event:\n",
    "#             pdb.set_trace()\n",
    "            word_lemma = wnl.lemmatize(word.lower(),get_wordnet_pos(pos))\n",
    "            lemma_event.append(word_lemma)\n",
    "            dic_bow[word_lemma] += 1\n",
    "        preprocess_events_tokens.append(lemma_event,)\n",
    "        preprocess_events.append(' '.join(lemma_event))\n",
    "        preprocess_BOW_events.append(dic_bow)\n",
    "    return preprocess_events_tokens,preprocess_events,preprocess_BOW_events\n",
    "\n",
    "preprocess_train_events_tokens,preprocessed_train_events,preprocessed_train_BOW_events = preprocess_stopwords_lemma_evnets(misinfo_train_events)\n",
    "preprocess_dev_events_tokens,preprocessed_dev_events,preprocessed_dev_BOW_events = preprocess_stopwords_lemma_evnets(dev_events)\n",
    "preprocess_test_events_tokens,preprocessed_test,preprocessed_test_BOW = preprocess_stopwords_lemma_evnets(test_unlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocess_train_events_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "\n",
    "    def __init__(self, word_model):\n",
    "        self.word_model = word_model\n",
    "        self.vector_size = word_model.wv.vector_size\n",
    "\n",
    "    def fit(self):  # comply with scikit-learn transformer requirement\n",
    "        return self\n",
    "\n",
    "    def transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        doc_word_vector = self.word_average_list(docs)\n",
    "        return doc_word_vector\n",
    "\n",
    "    def word_average(self, sent):\n",
    "        \"\"\"\n",
    "        Compute average word vector for a single doc/sentence.\n",
    "\n",
    "\n",
    "        :param sent: list of sentence tokens\n",
    "        :return:\n",
    "            mean: float of averaging word vectors\n",
    "        \"\"\"\n",
    "        mean = []\n",
    "        for word in sent:\n",
    "            if word in self.word_model.wv.vocab:\n",
    "                mean.append(self.word_model.wv.get_vector(word))\n",
    "\n",
    "        if not mean:  # empty words\n",
    "            # If a text is empty, return a vector of zeros.\n",
    "            logging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "            return np.zeros(self.vector_size)\n",
    "        else:\n",
    "            mean = np.array(mean).mean(axis=0)\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def word_average_list(self, docs):\n",
    "        \"\"\"\n",
    "        Compute average word vector for multiple docs, where docs had been tokenized.\n",
    "\n",
    "        :param docs: list of sentence in list of separated tokens\n",
    "        :return:\n",
    "            array of average word vector in shape (len(docs),)\n",
    "        \"\"\"\n",
    "        return np.vstack([self.word_average(sent) for sent in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "\n",
    "    def __init__(self, word_model):\n",
    "\n",
    "        self.word_model = word_model\n",
    "        self.word_idf_weight = None\n",
    "        self.vector_size = word_model.wv.vector_size\n",
    "\n",
    "    def fit(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        \"\"\"\n",
    "        Fit in a list of docs, which had been preprocessed and tokenized,\n",
    "        such as word bi-grammed, stop-words removed, lemmatized, part of speech filtered.\n",
    "        Then build up a tfidf model to compute each word's idf as its weight.\n",
    "        Noted that tf weight is already involved when constructing average word vectors, and thus omitted.\n",
    "        :param\n",
    "            pre_processed_docs: list of docs, which are tokenized\n",
    "        :return:\n",
    "            self\n",
    "        \"\"\"\n",
    "\n",
    "        text_docs = []\n",
    "        for doc in docs:\n",
    "            text_docs.append(\" \".join(doc))\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tfidf.fit(text_docs)  # must be list of text string\n",
    "\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of\n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)  # used as default value for defaultdict\n",
    "        self.word_idf_weight = defaultdict(lambda: max_idf,[(word, tfidf.idf_[i]) for word, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        doc_word_vector = self.word_average_list(docs)\n",
    "        return doc_word_vector\n",
    "\n",
    "\n",
    "    def word_average(self, sent):\n",
    "        \"\"\"\n",
    "        Compute average word vector for a single doc/sentence.\n",
    "        :param sent: list of sentence tokens\n",
    "        :return:\n",
    "            mean: float of averaging word vectors\n",
    "        \"\"\"\n",
    "\n",
    "        mean = []\n",
    "        for word in sent:\n",
    "            if word in self.word_model.wv.vocab:\n",
    "                mean.append(self.word_model.wv.get_vector(word) * self.word_idf_weight[word])  # idf weighted\n",
    "\n",
    "        if not mean:  # empty words\n",
    "            # If a text is empty, return a vector of zeros.\n",
    "            logging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "            return np.zeros(self.vector_size)\n",
    "        else:\n",
    "            mean = np.array(mean).mean(axis=0)\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def word_average_list(self, docs):\n",
    "        \"\"\"\n",
    "        Compute average word vector for multiple docs, where docs had been tokenized.\n",
    "        :param docs: list of sentence in list of separated tokens\n",
    "        :return:\n",
    "            array of average word vector in shape (len(docs),)\n",
    "        \"\"\"\n",
    "        return np.vstack([self.word_average(sent) for sent in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-93bcb5a27a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_vec_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_vec_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_vec_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_vec_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_model' is not defined"
     ]
    }
   ],
   "source": [
    "mean_vec_tr = MeanEmbeddingVectorizer(word_model)\n",
    "train_vec = mean_vec_tr.transform(train_tokenized)\n",
    "dev_vec = mean_vec_tr.transform(dev_tokenized)\n",
    "test_vec = mean_vec_tr.transform(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "mean_vec_tr_skip_gram = MeanEmbeddingVectorizer(word_model_skip_gram)\n",
    "train_vec_skip_gram = mean_vec_tr_skip_gram.transform(preprocess_train_events_tokens)\n",
    "dev_vec_skip_gram = mean_vec_tr_skip_gram.transform(preprocess_dev_events_tokens)\n",
    "test_vec_skip_gram = mean_vec_tr_skip_gram.transform(preprocess_test_events_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5050505050505051\n",
      "Recall    = 1.0\n",
      "F1        = 0.6711409395973155\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5050505050505051\n",
      "Recall    = 1.0\n",
      "F1        = 0.6711409395973155\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5050505050505051\n",
      "Recall    = 1.0\n",
      "F1        = 0.6711409395973155\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5632183908045977\n",
      "Recall    = 0.98\n",
      "F1        = 0.7153284671532847\n",
      "0.61\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 0.98\n",
      "F1        = 0.6621621621621622\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 0.98\n",
      "F1        = 0.6621621621621622\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5051546391752577\n",
      "Recall    = 0.98\n",
      "F1        = 0.6666666666666666\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5632183908045977\n",
      "Recall    = 0.98\n",
      "F1        = 0.7153284671532847\n",
      "0.61\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5647058823529412\n",
      "Recall    = 0.96\n",
      "F1        = 0.711111111111111\n",
      "0.61\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5647058823529412\n",
      "Recall    = 0.96\n",
      "F1        = 0.711111111111111\n",
      "0.61\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5647058823529412\n",
      "Recall    = 0.96\n",
      "F1        = 0.711111111111111\n",
      "0.61\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5925925925925926\n",
      "Recall    = 0.96\n",
      "F1        = 0.732824427480916\n",
      "0.65\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5384615384615384\n",
      "Recall    = 0.98\n",
      "F1        = 0.6950354609929078\n",
      "0.57\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5384615384615384\n",
      "Recall    = 0.98\n",
      "F1        = 0.6950354609929078\n",
      "0.57\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5384615384615384\n",
      "Recall    = 0.98\n",
      "F1        = 0.6950354609929078\n",
      "0.57\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5384615384615384\n",
      "Recall    = 0.98\n",
      "F1        = 0.6950354609929078\n",
      "0.57\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5454545454545454\n",
      "Recall    = 0.96\n",
      "F1        = 0.6956521739130435\n",
      "0.58\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5454545454545454\n",
      "Recall    = 0.96\n",
      "F1        = 0.6956521739130435\n",
      "0.58\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5454545454545454\n",
      "Recall    = 0.96\n",
      "F1        = 0.6956521739130435\n",
      "0.58\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5454545454545454\n",
      "Recall    = 0.96\n",
      "F1        = 0.6956521739130435\n",
      "0.58\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6333333333333333\n",
      "Recall    = 0.76\n",
      "F1        = 0.6909090909090909\n",
      "0.66\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6333333333333333\n",
      "Recall    = 0.76\n",
      "F1        = 0.6909090909090909\n",
      "0.66\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6333333333333333\n",
      "Recall    = 0.76\n",
      "F1        = 0.6909090909090909\n",
      "0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6333333333333333\n",
      "Recall    = 0.76\n",
      "F1        = 0.6909090909090909\n",
      "0.66\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "nus = [0.001, 0.01, 0.1, 1]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['rbf','linear']\n",
    "for kernel in kernels:\n",
    "    for nu in nus:\n",
    "        for gamma in gammas:\n",
    "            ocs = svm.OneClassSVM(gamma=gamma,kernel = kernel, nu = nu).fit(train_vec_skip_gram)\n",
    "            y_pre = ocs.predict(dev_vec_skip_gram)\n",
    "            print(ocs)\n",
    "            evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "ocs = svm.OneClassSVM(gamma=1,kernel = 'linear', nu = 0.1).fit(train_vec_skip_gram)\n",
    "test_pres = ocs.predict(test_vec_skip_gram)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-556\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_tr = TfidfEmbeddingVectorizer(word_model)\n",
    "tfidf_vec_tr.fit(train_tokenized)  # fit tfidf model first\n",
    "tfidf_train_vec = tfidf_vec_tr.transform(train_tokenized)\n",
    "tfidf_dev_vec = tfidf_vec_tr.transform(dev_tokenized)\n",
    "tfidf_test_vec = tfidf_vec_tr.transform(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:53: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec_tr_skip_gram = TfidfEmbeddingVectorizer(word_model_skip_gram)\n",
    "tfidf_vec_tr_skip_gram.fit(preprocess_train_events_tokens)  # fit tfidf model first\n",
    "tfidf_train_vec_skip_gram = tfidf_vec_tr_skip_gram.transform(preprocess_train_events_tokens)\n",
    "tfidf_dev_vec_skip_gram = tfidf_vec_tr_skip_gram.transform(preprocess_dev_events_tokens)\n",
    "tfidf_test_vec_skip_gram = tfidf_vec_tr_skip_gram.transform(preprocess_test_events_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.532608695652174\n",
      "Recall    = 0.98\n",
      "F1        = 0.6901408450704226\n",
      "0.56\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6197183098591549\n",
      "Recall    = 0.88\n",
      "F1        = 0.7272727272727273\n",
      "0.67\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 1.0\n",
      "Recall    = 0.02\n",
      "F1        = 0.0392156862745098\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5268817204301075\n",
      "Recall    = 0.98\n",
      "F1        = 0.6853146853146853\n",
      "0.55\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5384615384615384\n",
      "Recall    = 0.98\n",
      "F1        = 0.6950354609929078\n",
      "0.57\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.625\n",
      "Recall    = 0.9\n",
      "F1        = 0.7377049180327869\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 1.0\n",
      "Recall    = 0.02\n",
      "F1        = 0.0392156862745098\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5875\n",
      "Recall    = 0.94\n",
      "F1        = 0.7230769230769232\n",
      "0.64\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5875\n",
      "Recall    = 0.94\n",
      "F1        = 0.7230769230769232\n",
      "0.64\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.625\n",
      "Recall    = 0.9\n",
      "F1        = 0.7377049180327869\n",
      "0.68\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 1.0\n",
      "Recall    = 0.02\n",
      "F1        = 0.0392156862745098\n",
      "0.51\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='rbf',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.001, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.4897959183673469\n",
      "Recall    = 0.96\n",
      "F1        = 0.6486486486486486\n",
      "0.48\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.4897959183673469\n",
      "Recall    = 0.96\n",
      "F1        = 0.6486486486486486\n",
      "0.48\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.4897959183673469\n",
      "Recall    = 0.96\n",
      "F1        = 0.6486486486486486\n",
      "0.48\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.4897959183673469\n",
      "Recall    = 0.96\n",
      "F1        = 0.6486486486486486\n",
      "0.48\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=1, kernel='linear',\n",
      "            max_iter=-1, nu=1, shrinking=True, tol=0.001, verbose=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "F1        = 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nus = [0.001, 0.01, 0.1, 1]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['rbf','linear']\n",
    "for kernel in kernels:\n",
    "    for nu in nus:\n",
    "        for gamma in gammas:\n",
    "            ocs = svm.OneClassSVM(gamma=gamma,kernel = kernel, nu = nu).fit(tfidf_train_vec_skip_gram)\n",
    "            y_pre = ocs.predict(tfidf_dev_vec_skip_gram)\n",
    "            print(ocs)\n",
    "            evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "ocs = svm.OneClassSVM(gamma=0.1,kernel = 'rbf', nu = 0.01).fit(tfidf_train_vec_skip_gram)\n",
    "test_pres = ocs.predict(tfidf_test_vec_skip_gram)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-674\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "ocs = svm.OneClassSVM(gamma=0.1,kernel = 'rbf', nu = 0.1).fit(tfidf_train_vec_skip_gram)\n",
    "test_pres = ocs.predict(tfidf_test_vec_skip_gram)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-674\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5853658536585366\n",
      "Recall    = 0.96\n",
      "F1        = 0.7272727272727272\n",
      "0.64\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.640625\n",
      "Recall    = 0.82\n",
      "F1        = 0.7192982456140351\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.7619047619047619\n",
      "Recall    = 0.64\n",
      "F1        = 0.6956521739130435\n",
      "0.72\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5853658536585366\n",
      "Recall    = 0.96\n",
      "F1        = 0.7272727272727272\n",
      "0.64\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6507936507936508\n",
      "Recall    = 0.82\n",
      "F1        = 0.7256637168141592\n",
      "0.69\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.7272727272727273\n",
      "Recall    = 0.64\n",
      "F1        = 0.6808510638297872\n",
      "0.7\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5853658536585366\n",
      "Recall    = 0.96\n",
      "F1        = 0.7272727272727272\n",
      "0.64\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6376811594202898\n",
      "Recall    = 0.88\n",
      "F1        = 0.7394957983193275\n",
      "0.69\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6808510638297872\n",
      "Recall    = 0.64\n",
      "F1        = 0.6597938144329897\n",
      "0.67\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5925925925925926\n",
      "Recall    = 0.96\n",
      "F1        = 0.732824427480916\n",
      "0.65\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6428571428571429\n",
      "Recall    = 0.9\n",
      "F1        = 0.75\n",
      "0.7\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.673469387755102\n",
      "Recall    = 0.66\n",
      "F1        = 0.6666666666666666\n",
      "0.67\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6\n",
      "Recall    = 0.96\n",
      "F1        = 0.7384615384615384\n",
      "0.66\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6266666666666667\n",
      "Recall    = 0.94\n",
      "F1        = 0.752\n",
      "0.69\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6724137931034483\n",
      "Recall    = 0.78\n",
      "F1        = 0.7222222222222223\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "n_neighborss = [10,20,30,40,100]\n",
    "contaminations = [0.1,0.3,0.5]\n",
    "for n_neighbor in n_neighborss:\n",
    "    for contamination in contaminations:\n",
    "        clf = LocalOutlierFactor(n_neighbors = n_neighbor, novelty=True, contamination=contamination)\n",
    "        clf.fit(train_vec_skip_gram)\n",
    "        y_pre = clf.predict(dev_vec_skip_gram)\n",
    "        print(clf)\n",
    "        evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5897435897435898\n",
      "Recall    = 0.92\n",
      "F1        = 0.71875\n",
      "0.64\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6851851851851852\n",
      "Recall    = 0.74\n",
      "F1        = 0.7115384615384615\n",
      "0.7\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=10, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.8\n",
      "Recall    = 0.56\n",
      "F1        = 0.6588235294117648\n",
      "0.71\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6052631578947368\n",
      "Recall    = 0.92\n",
      "F1        = 0.7301587301587301\n",
      "0.66\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6779661016949152\n",
      "Recall    = 0.8\n",
      "F1        = 0.7339449541284404\n",
      "0.71\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=20, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.725\n",
      "Recall    = 0.58\n",
      "F1        = 0.6444444444444445\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.618421052631579\n",
      "Recall    = 0.94\n",
      "F1        = 0.746031746031746\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6612903225806451\n",
      "Recall    = 0.82\n",
      "F1        = 0.7321428571428572\n",
      "0.7\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=30, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.725\n",
      "Recall    = 0.58\n",
      "F1        = 0.6444444444444445\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6153846153846154\n",
      "Recall    = 0.96\n",
      "F1        = 0.7500000000000001\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6507936507936508\n",
      "Recall    = 0.82\n",
      "F1        = 0.7256637168141592\n",
      "0.69\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=40, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6956521739130435\n",
      "Recall    = 0.64\n",
      "F1        = 0.6666666666666666\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.1, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.618421052631579\n",
      "Recall    = 0.94\n",
      "F1        = 0.746031746031746\n",
      "0.68\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.3, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.65625\n",
      "Recall    = 0.84\n",
      "F1        = 0.736842105263158\n",
      "0.7\n",
      "LocalOutlierFactor(algorithm='auto', contamination=0.5, leaf_size=30,\n",
      "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
      "                   n_neighbors=100, novelty=True, p=2)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.6862745098039216\n",
      "Recall    = 0.7\n",
      "F1        = 0.693069306930693\n",
      "0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "n_neighborss = [10,20,30,40,100]\n",
    "contaminations = [0.1,0.3,0.5]\n",
    "for n_neighbor in n_neighborss:\n",
    "    for contamination in contaminations:\n",
    "        clf = LocalOutlierFactor(n_neighbors = n_neighbor, novelty=True, contamination=contamination)\n",
    "        clf.fit(tfidf_train_vec_skip_gram)\n",
    "        y_pre = clf.predict(tfidf_dev_vec_skip_gram)\n",
    "        print(clf)\n",
    "        evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "clf = LocalOutlierFactor(n_neighbors = 40, novelty=True, contamination=0.1)\n",
    "clf.fit(tfidf_train_vec_skip_gram)\n",
    "test_pres = clf.predict(tfidf_test_vec_skip_gram)\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
