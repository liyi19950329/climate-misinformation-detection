{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. File downloaded: project-files.zip\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# fname = 'project-files.zip'\n",
    "# data_dir = os.path.splitext(fname)[0] #'project-files'\n",
    "\n",
    "# my_file = Path(fname)\n",
    "# if not my_file.is_file():\n",
    "#     url = \"https://github.com/jhlau/jhlau.github.io/blob/master/files/rumour-data.tgz?raw=true\"\n",
    "#     r = requests.get(url)\n",
    "\n",
    "#     #Save to the current directory\n",
    "#     with open(fname, 'wb') as f:\n",
    "#         f.write(r.content)\n",
    "        \n",
    "# print(\"Done. File downloaded:\", my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction done.\n"
     ]
    }
   ],
   "source": [
    "# import shutil\n",
    "# # import time\n",
    "\n",
    "# # decompress project-files.zip\n",
    "# def unzip_it(f):\n",
    "#     shutil.unpack_archive(f, os.getcwd())  # decompress to folder\n",
    "    \n",
    "# unzip_it(fname)\n",
    "# # time.sleep(3)\n",
    "\n",
    "# #remove superfluous files (e.g. .DS_store)\n",
    "# extra_files = []\n",
    "# for r, d, f in os.walk(data_dir):\n",
    "#     for file in f:\n",
    "#         if (file.startswith(\".\")):\n",
    "#             extra_files.append(os.path.join(r, file))\n",
    "# for f in extra_files:\n",
    "#     os.remove(f)\n",
    "    \n",
    "# print(\"Extraction done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. File downloaded: rumour-data.tgz\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "fname = 'rumour-data.tgz'\n",
    "data_dir = os.path.splitext(fname)[0] #'rumour-data'\n",
    "\n",
    "my_file = Path(fname)\n",
    "if not my_file.is_file():\n",
    "    url = \"https://github.com/jhlau/jhlau.github.io/blob/master/files/rumour-data.tgz?raw=true\"\n",
    "    r = requests.get(url)\n",
    "\n",
    "    #Save to the current directory\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "print(\"Done. File downloaded:\", my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction done.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "#decompress rumour-data.tgz\n",
    "tar = tarfile.open(fname, \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "#remove superfluous files (e.g. .DS_store)\n",
    "extra_files = []\n",
    "for r, d, f in os.walk(data_dir):\n",
    "    for file in f:\n",
    "        if (file.startswith(\".\")):\n",
    "            extra_files.append(os.path.join(r, file))\n",
    "for f in extra_files:\n",
    "    os.remove(f)\n",
    "\n",
    "print(\"Extraction done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "def get_tweet_text_from_json(file_path):\n",
    "    events = []\n",
    "    labels = []\n",
    "    with open(file_path) as json_file:\n",
    "#         pdb.set_trace()\n",
    "        data = json.load(json_file)\n",
    "        for key, value in data.items():\n",
    "            events.append(value[\"text\"])\n",
    "            labels.append(value[\"label\"])\n",
    "        return events,labels\n",
    "    \n",
    "def get_tweet_text_from_json_unlabel(file_path):\n",
    "    events = []\n",
    "    with open(file_path) as json_file:\n",
    "#         pdb.set_trace()\n",
    "        data = json.load(json_file)\n",
    "        for key, value in data.items():\n",
    "            events.append(value[\"text\"])\n",
    "        return events\n",
    "    \n",
    "def get_tweet_text_from_json_hh(file_path):\n",
    "    with open(file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data[\"text\"]\n",
    "\n",
    "# re.search('\\.json$', event):\n",
    "def get_events(event_dir):\n",
    "    event_list = []\n",
    "    path1 = Path(event_dir)\n",
    "    all_json_file = list(path1.glob('**/*.json'))\n",
    "    for event in sorted(os.listdir(event_dir)):\n",
    "        ###\n",
    "        # Your answer BEGINS HERE\n",
    "        ###\n",
    "#         pdb.set_trace()\n",
    "        if event == \".DS_Store\":\n",
    "            continue\n",
    "        if event.endswith(\"json\"):\n",
    "            event_list.append(get_tweet_text_from_json_hh(os.path.join(event_dir, event)))\n",
    "        else:\n",
    "            event_list.append(get_events(os.path.join(event_dir, event)))\n",
    "\n",
    "        event_dir_last = event_dir.split(\"/\")[len(event_dir.split(\"/\")) - 1]\n",
    "        if (event_dir_last not in [\"rumours\",\"non-rumours\",\"reactions\",\"source-tweet\"]) and len(event_list) == 2:\n",
    "            event_list = event_list[0] + event_list[1]\n",
    "        ###\n",
    "        # Your answer ENDS HERE\n",
    "        ###\n",
    "    return event_list\n",
    "    \n",
    "\n",
    "nonrumour_events = get_events(os.path.join(data_dir, \"non-rumours\"))\n",
    "nonrumour_labels = np.zeros(len(nonrumour_events),dtype=np.int8).tolist()\n",
    "for i,nonrumour_event in enumerate(nonrumour_events):\n",
    "    nonrumour_events[i] = ' '.join(nonrumour_event)\n",
    "\n",
    "print(\"Number of non-rumour events =\", len(nonrumour_events))\n",
    "corinfo_train_events,corinfo_train_labels = get_tweet_text_from_json(\"train_negs.json\")\n",
    "misinfo_train_events,misinfo_train_labels = get_tweet_text_from_json(\"train.json\")\n",
    "train_events, train_labels = corinfo_train_events + misinfo_train_events,corinfo_train_labels + misinfo_train_labels\n",
    "dev_events,dev_labels = get_tweet_text_from_json(\"dev.json\")\n",
    "test_unlabel = get_tweet_text_from_json_unlabel(\"test-unlabelled.json\")\n",
    "\n",
    "train_nonrumour_events, train_nonrumour_labels = train_events + nonrumour_events,train_labels + nonrumour_labels\n",
    "# print(misinfo_train_events[0])\n",
    "# print(len(misinfo_train_events),len(misinfo_train_labels))\n",
    "# print(len(dev_events),len(dev_labels))\n",
    "# print(len(test_unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_nonrumour_events))\n",
    "# print(train_nonrumour_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215\n",
      "1215\n",
      "100\n",
      "1410\n"
     ]
    }
   ],
   "source": [
    "print(len(train_events))\n",
    "print(len(train_labels))\n",
    "print(len(dev_events))\n",
    "print(len(test_unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_events(events):\n",
    "    preprocessed_events = []\n",
    "#     pdb.set_trace()\n",
    "    for event in events:\n",
    "        \n",
    "        dic_bow = defaultdict(int)\n",
    "        for word in tt.tokenize(event):\n",
    "            if word.lower() not in stopwords:\n",
    "                dic_bow[word] = dic_bow[word] + 1\n",
    "            else:\n",
    "                continue  \n",
    "        preprocessed_events.append(dic_bow)\n",
    "    return preprocessed_events\n",
    "\n",
    "preprocessed_train_events = preprocess_events(train_nonrumour_events)\n",
    "preprocessed_dev_events = preprocess_events(dev_events)\n",
    "preprocessed_test = preprocess_events(test_unlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2215\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed_train_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hashtags(events):\n",
    "    hashtags = set([])\n",
    "    for event in events:\n",
    "        for word, frequency in event.items():\n",
    "            if word.startswith(\"#\"):\n",
    "                hashtags.add(word)\n",
    "    return hashtags\n",
    "\n",
    "hashtags = get_all_hashtags(preprocessed_train_events + preprocessed_dev_events + preprocessed_test)\n",
    "# print(\"Number of hashtags =\", len(hashtags))\n",
    "# print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words()) #a list of words provided by NLTK\n",
    "\n",
    "# lowercase the words lib\n",
    "words_lowercase = set([])\n",
    "for word in words:\n",
    "    words_lowercase.add(word.lower())\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.tag.pos_tag(word,tagset=\"universal\")[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def tokenize_hashtags_help(hashtag,hashtage_tokens):\n",
    "    if hashtag == '#':\n",
    "        hashtage_tokens.append('#')\n",
    "    elif len(hashtag) >= 1:\n",
    "        instant = ''\n",
    "        for i in range(len(hashtag) - 1, 0, -1):\n",
    "            lemma = lemmatizer.lemmatize(hashtag[-(i):].lower(),get_wordnet_pos([hashtag[-(i):].lower()]))\n",
    "            if lemma in words_lowercase:\n",
    "                instant = hashtag[-(i):]\n",
    "                break\n",
    "        if len(instant) == 0:\n",
    "            instant = hashtag[-1]\n",
    "        hashtage_tokens.append(instant)\n",
    "        tokenize_hashtags_help(hashtag[:-len(instant)], hashtage_tokens)\n",
    "        \n",
    "def tokenize_hashtags(hashtags):\n",
    "    tokenized_hashtags = defaultdict(list)\n",
    "    for hashtag in hashtags:\n",
    "        hashtage_tokens = []\n",
    "        tokenize_hashtags_help(hashtag, hashtage_tokens)\n",
    "        hashtage_tokens.reverse()\n",
    "        tokenized_hashtags[hashtag] = hashtage_tokens\n",
    "    return tokenized_hashtags\n",
    "\n",
    "tokenized_hashtags = tokenize_hashtags(hashtags)\n",
    "# print(len(tokenized_hashtags))\n",
    "# print(tokenized_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_event(event_extra, hashtag_tokens, freq):\n",
    "    for hashtag_token in hashtag_tokens:\n",
    "        event_extra[hashtag_token] += freq\n",
    "    return\n",
    "\n",
    "def update_event_bow(events):\n",
    "    for i,event in enumerate(events):\n",
    "        event_extra = event.copy()\n",
    "        for hashtag in hashtags:\n",
    "            if event[hashtag] == 0:\n",
    "                event.pop(hashtag)\n",
    "            else:\n",
    "#                 pdb.set_trace()\n",
    "                hashtag_tokens = tokenized_hashtags[hashtag]\n",
    "                update_event(event_extra, hashtag_tokens, event_extra[hashtag])\n",
    "#         pdb.set_trace()\n",
    "        events[i] = event_extra\n",
    "    return\n",
    "\n",
    "update_event_bow(preprocessed_train_events)\n",
    "update_event_bow(preprocessed_dev_events) \n",
    "update_event_bow(preprocessed_test)\n",
    "# print(preprocessed_misinfo_train_events[0])\n",
    "# print(len(preprocessed_misinfo_train_events))\n",
    "# print(len(preprocessed_dev_events))\n",
    "# print(len(preprocessed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preprocessed_train_events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = 0\n",
    "# for i,label in enumerate(dev_labels):\n",
    "# #     pdb.set_trace()\n",
    "#     if label == 0:\n",
    "#         dev_labels[i] = -1\n",
    "#         outliers += 1\n",
    "# outliers_fraction = outliers / len(dev_labels)\n",
    "# print(outliers_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 57295\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "x = preprocessed_train_events + preprocessed_dev_events\n",
    "\n",
    "# test_fold = np.concatenate([\n",
    "#     # The training data.\n",
    "#     np.full(len(preprocessed_misinfo_train_events),-1, dtype=np.int8),\n",
    "#     # The development data.\n",
    "#     np.zeros(len(preprocessed_dev_events), dtype=np.int8)\n",
    "# ])\n",
    "\n",
    "\n",
    "vectorizer.fit(x)\n",
    "vector_train = vectorizer.transform(preprocessed_train_events)\n",
    "vector_development = vectorizer.transform(preprocessed_dev_events)\n",
    "vector_test = vectorizer.transform(preprocessed_test)\n",
    "# print(list(vectorizer.vocabulary_.keys())[:10])\n",
    "print(\"Vocabulary size =\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn import svm\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "\n",
    "# nus = [0.001, 0.01, 0.1, 1]\n",
    "# gammas = [0.001, 0.01, 0.1, 1]\n",
    "# kernels = ['rbf','linear']\n",
    "# tuned_parameters_ocsvm = {'kernel' : ['rbf','linear'], 'gamma' : gammas, 'nu': nus}\n",
    "\n",
    "# # print(sorted(sklearn.metrics.SCORERS.keys()))\n",
    "# def best_parameter(classifer,tuned_parameter,train_feature,train_label):\n",
    "#     scores = ['precision_macro', 'recall_macro','accuracy']\n",
    "#     print(classifer)\n",
    "#     for score in scores:\n",
    "#         clf = GridSearchCV(classifer, tuned_parameters, cv = cv,\n",
    "#                                scoring = score, return_train_score = True)\n",
    "#         clf.fit(train_feature,train_label)\n",
    "#         print(score)\n",
    "# #         resultDf = pd.DataFrame(clf.cv_results_)\n",
    "# #         print(resultDf[[\"mean_test_score\", \"std_test_score\", \"params\"]].sort_values(by=[\"mean_test_score\"], ascending=False).head())\n",
    "#         print(\"Best parameters set found on development set:\")\n",
    "#         print()\n",
    "#         print(clf.best_params_)\n",
    "#     return clf.best_params_\n",
    "\n",
    "# clf_ocsvm = best_parameter(svm.OneClassSVM(),tuned_parameters_ocsvm,vector_train,y)\n",
    "\n",
    "\n",
    "# #     y_true, y_pred = dev_labels, clf.predict(vector_development)\n",
    "# #     print(classification_report(y_true, y_pred))\n",
    "# #     print(accuracy_score(y_true,y_pred))\n",
    "# #     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_accuracy = svm.OneClassSVM(gamma=0.001,kernel = 'linear', nu = 0.001).fit(vector_train)\n",
    "# clf_precision = svm.OneClassSVM(gamma=0.01,kernel = 'rbf', nu = 0.001).fit(vector_train)\n",
    "# y_pre_accuracy = clf_accuracy.predict(vector_test)\n",
    "# y_pre_precision = clf_precision.predict(vector_test)\n",
    "# for i in y_pre_accuracy:\n",
    "#     if i == -1:\n",
    "#         print(i)\n",
    "# print()\n",
    "# j = 0\n",
    "# for i in y_pre_precision:\n",
    "#     if i == -1:\n",
    "#         j += 1\n",
    "# print(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def evaluate_result(groundtruth, prediction):\n",
    "    prediction = prediction.tolist()\n",
    "    for i,item in enumerate(prediction):\n",
    "        if item == -1:\n",
    "            prediction[i] = 0\n",
    "    p, r, f, _ = precision_recall_fscore_support(groundtruth, prediction, pos_label=1, average=\"binary\")\n",
    "#     pdb.set_trace()\n",
    "    print(\"Performance on the positive class (documents with misinformation):\")\n",
    "    print(\"Precision =\", p)\n",
    "    print(\"Recall    =\", r)\n",
    "    print(\"F1        =\", f)\n",
    "    print(accuracy_score(dev_labels,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn import svm\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "# nus = [0.001, 0.01, 0.1, 1]\n",
    "# gammas = [0.001, 0.01, 0.1, 1]\n",
    "# kernels = ['rbf','linear']\n",
    "# for kernel in kernels:\n",
    "#     for nu in nus:\n",
    "#         for gamma in gammas:\n",
    "#             clf = svm.OneClassSVM(gamma=gamma,kernel = kernel, nu = nu).fit(train_set)\n",
    "#             y_pre = clf.predict(vector_development)\n",
    "#             print(clf)\n",
    "#             evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.OneClassSVM(gamma=0.001,kernel = 'rbf', nu = 0.001).fit(train_set)\n",
    "test_pres = clf.predict(vector_test)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n"
     ]
    }
   ],
   "source": [
    "print(len(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_output(preds):\n",
    "    test_dic = {}\n",
    "    for i,test_pre in enumerate(preds):\n",
    "        if test_pre == -1:\n",
    "            dic = {}\n",
    "            dic['label'] = 0\n",
    "    #         pdb.set_trace()\n",
    "            test_dic['test-%s'%(i)] = dic\n",
    "        else:\n",
    "            dic = {}\n",
    "    #         pdb.set_trace()\n",
    "            dic['label'] = 1\n",
    "            test_dic['test-%s'%(i)] = dic\n",
    "    jstr = json.dumps(test_dic,ensure_ascii = False)\n",
    "    # print(jstr)\n",
    "    with open('test-output.json','w') as f:\n",
    "        f.write(jstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf = True,use_idf = True)\n",
    "train_set_tfidf = tfidf_transformer.fit_transform(train_set)\n",
    "dev_set = tfidf_transformer.transform(vector_development)\n",
    "test_set = tfidf_transformer.transform(vector_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kernel in kernels:\n",
    "#     for nu in nus:\n",
    "#         for gamma in gammas:\n",
    "#             clf = svm.OneClassSVM(gamma=gamma,kernel = kernel, nu = nu).fit(train_set_tfidf)\n",
    "#             y_pre = clf.predict(dev_set)\n",
    "#             print(clf)\n",
    "#             evaluate_result(dev_labels,y_pre)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.OneClassSVM(gamma=1,kernel = 'rbf', nu = 0.001).fit(train_set_tfidf)\n",
    "test_pres = clf.predict(test_set)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####IsolationForest####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.01,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.1,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5052631578947369\n",
      "Recall    = 0.96\n",
      "F1        = 0.6620689655172414\n",
      "0.51\n",
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.2,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5476190476190477\n",
      "Recall    = 0.92\n",
      "F1        = 0.6865671641791046\n",
      "0.58\n",
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.3,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5797101449275363\n",
      "Recall    = 0.8\n",
      "F1        = 0.6722689075630253\n",
      "0.61\n",
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.4,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5434782608695652\n",
      "Recall    = 0.5\n",
      "F1        = 0.5208333333333334\n",
      "0.54\n",
      "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.5,\n",
      "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
      "                n_jobs=None, random_state=0, verbose=0, warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 0.26\n",
      "F1        = 0.34210526315789475\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "# n_estimators = [10,50,100]\n",
    "# max_samples_features = [0.1,0.4,0.8,1.0]\n",
    "contaminations = [0.01,0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "for contamination in contaminations:\n",
    "    iso = IsolationForest(contamination=contamination, random_state = 0).fit(vector_train)\n",
    "    y_pre = iso.predict(vector_development)\n",
    "    print(iso)\n",
    "    evaluate_result(dev_labels,y_pre)\n",
    "    \n",
    "# for n_estimator in n_estimators:\n",
    "#     for max_sample in max_samples_features:\n",
    "#         for max_feature in max_samples_features:\n",
    "#             iso = IsolationForest(contamination=0.5,max_features=max_feature, max_samples=max_sample, n_estimators=n_estimator).fit(train_set_tfidf)\n",
    "#             y_pre = iso.predict(dev_set)\n",
    "#             print(iso)\n",
    "#             print(classification_report(dev_labels, y_pre))\n",
    "#             print(accuracy_score(dev_labels,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "clf = IsolationForest(contamination=0.3, random_state = 0).fit(vector_train)\n",
    "test_pres = clf.predict(vector_test)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for contamination in contaminations:\n",
    "#     iso = IsolationForest(contamination=contamination, random_state = 0).fit(train_set_tfidf)\n",
    "#     y_pre = iso.predict(dev_set)\n",
    "#     print(iso)\n",
    "#     evaluate_result(dev_labels,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 ...  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "clf = IsolationForest(contamination=0.2, random_state = 0).fit(train_set_tfidf)\n",
    "test_pres = clf.predict(test_set)\n",
    "\n",
    "print(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_output(test_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5154639175257731\n",
      "Recall    = 1.0\n",
      "F1        = 0.6802721088435374\n",
      "0.53\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5319148936170213\n",
      "Recall    = 1.0\n",
      "F1        = 0.6944444444444444\n",
      "0.56\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5263157894736842\n",
      "Recall    = 1.0\n",
      "F1        = 0.6896551724137931\n",
      "0.55\n",
      "LogisticRegression(C=0.53, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5263157894736842\n",
      "Recall    = 1.0\n",
      "F1        = 0.6896551724137931\n",
      "0.55\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5263157894736842\n",
      "Recall    = 1.0\n",
      "F1        = 0.6896551724137931\n",
      "0.55\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5319148936170213\n",
      "Recall    = 1.0\n",
      "F1        = 0.6944444444444444\n",
      "0.56\n",
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5319148936170213\n",
      "Recall    = 1.0\n",
      "F1        = 0.6944444444444444\n",
      "0.56\n",
      "MultinomialNB\n",
      "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 0.98\n",
      "F1        = 0.6621621621621622\n",
      "0.5\n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5051546391752577\n",
      "Recall    = 0.98\n",
      "F1        = 0.6666666666666666\n",
      "0.51\n",
      "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5157894736842106\n",
      "Recall    = 0.98\n",
      "F1        = 0.6758620689655174\n",
      "0.53\n",
      "MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=0.53, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=0.55, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=0.6, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=1.2, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=1.3, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5208333333333334\n",
      "Recall    = 1.0\n",
      "F1        = 0.684931506849315\n",
      "0.54\n",
      "MultinomialNB(alpha=2, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5154639175257731\n",
      "Recall    = 1.0\n",
      "F1        = 0.6802721088435374\n",
      "0.53\n",
      "MultinomialNB(alpha=10, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5102040816326531\n",
      "Recall    = 1.0\n",
      "F1        = 0.6756756756756758\n",
      "0.52\n",
      "MultinomialNB(alpha=50, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n",
      "MultinomialNB(alpha=100, class_prior=None, fit_prior=True)\n",
      "Performance on the positive class (documents with misinformation):\n",
      "Precision = 0.5\n",
      "Recall    = 1.0\n",
      "F1        = 0.6666666666666666\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "\n",
    "def do_multiple_test(clfs,train_feature,train_classes,development_feature, development_classes,name):\n",
    "    print(name)\n",
    "    for clf in clfs:\n",
    "#         pdb.set_trace()\n",
    "        print(clf[0])\n",
    "        clf[0].fit(train_feature,train_classes)\n",
    "        predictions = clf[0].predict(development_feature)\n",
    "        evaluate_result(development_classes,predictions)\n",
    "\n",
    "c_to_test_logistic = [0.001,0.01,0.1,0.5,0.53,1,100, 1000]\n",
    "lrcs = [(LogisticRegression(C=c), c) for c in c_to_test_logistic]\n",
    "\n",
    "c_to_test_nb = [0.001,0.01,0.1,0.5,0.53,0.55,0.6,1,1.2,1.3,2,10,50,100]\n",
    "nbcs = [(MultinomialNB(alpha=c), c) for c in c_to_test_nb]\n",
    "do_multiple_test(lrcs,vector_train,train_nonrumour_labels,vector_development, dev_labels,'LogisticRegression')\n",
    "do_multiple_test(nbcs,vector_train,train_nonrumour_labels,vector_development, dev_labels,'MultinomialNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "1297\n"
     ]
    }
   ],
   "source": [
    "lrc = LogisticRegression(C=1000)\n",
    "lrc.fit(vector_train,train_nonrumour_labels)\n",
    "test_pre = lrc.predict(vector_test)\n",
    "print(test_pre)\n",
    "print(sum(test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306\n"
     ]
    }
   ],
   "source": [
    "nbc = MultinomialNB(alpha=1.2)\n",
    "nbc.fit(vector_train,train_nonrumour_labels)\n",
    "test_pre = nbc.predict(vector_test)\n",
    "print(sum(test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
